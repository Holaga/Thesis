
% Example below
@inproceedings{raftAlg,
	author = {Ongaro, Diego and Ousterhout, John},
	title = {In Search of an Understandable Consensus Algorithm},
	booktitle = {Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference},
	series = {USENIX ATC'14},
	year = {2014},
	isbn = {978-1-931971-10-2},
	location = {Philadelphia, PA},
	pages = {305--320},
	numpages = {16},
	acmid = {2643666},
	publisher = {USENIX Association},
	address = {Berkeley, CA, USA},
}
% End of example

@article{brautaset2020acoustic,
  title={Acoustic classification in multifrequency echosounder data using deep convolutional neural networks},
  author={Brautaset, Olav and Waldeland, Anders Ueland and Johnsen, Espen and Malde, Ketil and Eikvil, Line and Salberg, Arnt-B{\o}rre and Handegard, Nils Olav},
  journal={ICES Journal of Marine Science},
  volume={77},
  number={4},
  pages={1391--1400},
  year={2020},
  publisher={Oxford University Press}
}

@article{johnsen2020measuring,
  title={Measuring distribution and density of sprat in {\AA}rdalsfjorden with a kayak drone-15-16 August 2020},
  author={Johnsen, Espen and Totland, Atle and Kvamme, Cecilie},
  journal={Rapport fra havforskningen},
  year={2020},
  publisher={Havforskningsinstituttet}
}

@misc{IMR, title={Quota advice}, url={https://www.hi.no/en/hi/radgivning/quota-advice-1}, journal={Institute of Marine Research}, publisher={Institute of Marine Research}, author={Institute of Marine Research},year = "2021 (accessed September 23, 2021)"} 

@misc{IMR-vessels, title={IMR-Vessels}, url={https://www.hi.no/en/hi/about-us/facilities/our-vessels}, journal={Institute of Marine Research}, publisher={Institute of Marine Research}, author={Institute of Marine Research},year = "2021 (accessed September 23, 2021)"}



@inbook{Goodfellow-et-al-2016_ML,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    pages        = "99",
    year={2016}
}

@inbook{Goodfellow-et-al-2016_generalization,
      title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    pages        = "110-116",
    year={2016}
  
}

@inbook{Goodfellow-et-al-2016_train_val_test_split,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    pages        = "120-121",
    year={2016}
}

@inbook{Goodfellow-et-al-2016_E,
      title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    pages        = "104-107",
    year={2016}
}

@misc{azure, title={What is Windows Azure?}, url={https://searchcloudcomputing.techtarget.com/definition/Windows-Azure}, publisher={TechTarget}, author={Stephen J. Bigelow},year = "2021 (accessed November 29, 2021)"
}

@misc{raw, title={What is a .RAW file?}, url={https://fileinfo.com/extension/raw}, publisher={fileinfo.com}, author={Unknown},year = "2021 (accessed November 29, 2021)"
}

@misc{docker, title={What is Docker?}, url={https://www.ibm.com/in-en/cloud/learn/docker}, publisher={International Business Machines Corporation (IBM)}, author={IBM Cloud Education},year = "2021 (accessed November 29, 2021)"
}

@misc{crimac_pipeline, title={CRIMAC pipeline - github}, url={https://github.com/CRIMAC-WP4-Machine-learning/CRIMAC-classifiers-unet}, publisher={Norwegian Computing Center and the Norwegian Institute of Marine Research as part of the research projects COGMAR and CRIMAC}, author={Nils Olav Handegaard, Ibrahim Umar, Alba Ordonez and Ingrid Utseth},year = "2021 (accessed November 29, 2021)"
}

@misc{lsss, title={Large Scale Survey System (LSSS)}, url={https://www.kongsberg.com/maritime/products/ocean-science/fishery-research/scientific-post-processing-applications/large-scale-survey-system-lsss/}, publisher={kongsberg}, author={Unknown},year = "2021 (accessed November 30, 2021)"
}

@misc{ices, title={ICES}, url={https://www.ices.dk/about-ICES/Pages/default.aspx}, publisher={International Council for the Exploration of the Sea}, author={Unknown},year = "2021 (accessed November 30, 2021)"
}

@misc{zarr, title={What is zarr?}, url={https://zarr.readthedocs.io/en/stable/}, publisher={Zarr Developers}, author={Unknown},year = "2021 (accessed November 30, 2021)"
}

@misc{xarray, title={What is xarray?}, url={http://xarray.pydata.org/en/stable/}, publisher={xarray Developers}, author={Unknown},year = "2021 (accessed November 30, 2021)"
}

@inbook{Goodfellow-et-al-2016_NN,
        title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    year={2016}
}

@misc{silver2017mastering,
      title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
      author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
      year={2017},
      eprint={1712.01815},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{razavi2021deep_exp_DL,
  title={Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling},
  author={Razavi, Saman},
  journal={Environmental Modelling \& Software},
  volume={144},
  pages={105159},
  year={2021},
  publisher={Elsevier}
}


@article{razavi2021deep_exp_per,
  title={Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling},
  author={Razavi, Saman},
  journal={Environmental Modelling \& Software},
  volume={144},
  pages={105159},
  year={2021},
  section={2.2}, 
  publisher={Elsevier}
}

@inproceedings{sharma2019new_activation_func,
    alias={A new activation function for deep neural network},
  title={A new activation function for deep neural network},
  author={Sharma, Ochin},
  booktitle={2019 international conference on machine learning, big data, cloud and parallel computing (COMITCon)},
  pages={84--86},
  year={2019},
  organization={IEEE}
}

@article{rajak2021segmentation,
  title={Segmentation of Polyp Instruments using UNet based deep learning model},
  author={Rajak, Rishav Kumar and Mirza, Ashar Beg},
  year={2021}
}

@inproceedings{unet_ronneberger2015,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@InProceedings{He_2017_ICCV_segmentation,
author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
title = {Mask R-CNN},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@article{o2015introduction_convolutions,
  title={An introduction to convolutional neural networks},
  author={O'Shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015}
}

@article{voulodimos2018deep_computer_vision,
  title={Deep learning for computer vision: A brief review},
  author={Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  journal={Computational intelligence and neuroscience},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}


@article{davis2014visual_deep_video_audio,
  title={The visual microphone: Passive recovery of sound from video},
  author={Davis, Abe and Rubinstein, Michael and Wadhwa, Neal and Mysore, Gautham J and Durand, Fredo and Freeman, William T},
  year={2014},
  publisher={Association for Computing Machinery (ACM)}
}

@inproceedings{wilson2001need_learning_rate,
  title={The need for small learning rates on large problems},
  author={Wilson, D Randall and Martinez, Tony R},
  booktitle={IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No. 01CH37222)},
  volume={1},
  pages={115--119},
  year={2001},
  organization={IEEE}
}

@inbook{Goodfellow-et-al-2016,

        title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = {5},
        pages        = "107-122",
    year={2016}
}


@inbook{Goodfellow-et-al-2016_learning_rate,
      title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 7,
    pages        = "238",
    year={2016}
  
}

@inbook{Goodfellow-et-al-2016_architecture,
        title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 6,
    pages        = {191-197},
    year={2016}
}

@inbook{Goodfellow-et-al-2016_SGD,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 5,
    pages        = {152},
    year={2016}
}


@inbook{Goodfellow-et-al-2016_gradient_descent,
      title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 4,
    pages        = {82-86},
    year={2016}
}


@inbook{Goodfellow-et-al-2016_convolution,
  
        title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 9,
    pages        = {331-333},
    year={2016}
}

@inbook{Goodfellow-et-al-2016_param_init,
  
        title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    chapter      = 8,
    pages        = {292-298},
    year={2016}
}

@inproceedings{wilson2000inefficiency_learning_rate,
  title={The inefficiency of batch training for large training sets},
  author={Wilson, D Randall and Martinez, Tony R},
  booktitle={Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium},
  volume={2},
  pages={113--117},
  year={2000},
  organization={IEEE}
}


@article{zhou2019mpce_cross_entropy,
  title={MPCE: a maximum probability based cross entropy loss function for neural network classification},
  author={Zhou, Yangfan and Wang, Xin and Zhang, Mingchuan and Zhu, Junlong and Zheng, Ruijuan and Wu, Qingtao},
  journal={IEEE Access},
  volume={7},
  pages={146331--146341},
  year={2019},
  publisher={IEEE}
}

@article{ho2019real_weighted_cross_entropy,
  title={The real-world-weight cross-entropy loss function: Modeling the costs of mislabeling},
  author={Ho, Yaoshiang and Wookey, Samuel},
  journal={IEEE Access},
  volume={8},
  pages={4806--4813},
  year={2019},
  publisher={IEEE}
}

@article{dumoulin2016guide_transposed_convolution,
  title={A guide to convolution arithmetic for deep learning},
  author={Dumoulin, Vincent and Visin, Francesco},
  journal={arXiv preprint arXiv:1603.07285},
  year={2016}
}

@article{kukavcka2017_regularization,
  title={Regularization for deep learning: A taxonomy},
  author={Kuka{\v{c}}ka, Jan and Golkov, Vladimir and Cremers, Daniel},
  journal={arXiv preprint arXiv:1710.10686},
  year={2017}
}

@article{lin2013network_in_network_1x1,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@article{rumelhart1986learning_backprop,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}


@article{powers2020evaluation_f1_recall_precision,
  title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
  author={Powers, David MW},
  journal={arXiv preprint arXiv:2010.16061},
  year={2020}
}


@InProceedings{pmlr-v37-ioffe15_batch_norm,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.}
}


@misc{pickle, title={What is a Python pickle?}, url={https://docs.python.org/3/library/pickle.html}, publisher={https://docs.python.org}, author={Unknown},year = "2022 (accessed March 09, 2022)"
}


@article{johnsen2017collective,
  title={Collective structures anchor massive schools of lesser sandeel to the seabed, increasing vulnerability to fishery},
  author={Johnsen, Espen and Rieucau, Guillaume and Ona, Egil and Skaret, Georg},
  journal={Marine Ecology Progress Series},
  volume={573},
  pages={229--236},
  year={2017}
}


@article{choi2021semi,
  title={Semi-supervised target classification in multi-frequency echosounder data},
  author={Choi, Changkyu and Kampffmeyer, Michael and Handegard, Nils Olav and Salberg, Arnt-B{\o}rre and Brautaset, Olav and Eikvil, Line and Jenssen, Robert},
  journal={ICES Journal of Marine Science},
  volume={78},
  number={7},
  pages={2615--2627},
  year={2021},
  publisher={Oxford University Press}
}

@article{mishra2017deep,
  title={Deep machine learning and neural networks: An overview},
  author={Mishra, Chandrahas and Gupta, DL},
  journal={IAES International Journal of Artificial Intelligence},
  volume={6},
  number={2},
  pages={66},
  year={2017},
  publisher={IAES Institute of Advanced Engineering and Science}
}


@inproceedings{farsal2018deep,
  title={Deep learning: An overview},
  author={Farsal, Wissal and Anter, Samir and Ramdani, Mohammed},
  booktitle={Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications},
  pages={1--6},
  year={2018}
}


@InProceedings{pmlr-v28-sutskever13,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1139--1147},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/sutskever13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/sutskever13.html},
  abstract = 	 {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.     Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.   }
}



@article{weng2019unet,
  title={Nas-unet: Neural architecture search for medical image segmentation},
  author={Weng, Yu and Zhou, Tianbao and Li, Yujie and Qiu, Xiaoyu},
  journal={IEEE Access},
  volume={7},
  pages={44247--44257},
  year={2019},
  publisher={IEEE}
}

@incollection{zhou2018unet,
  title={Unet++: A nested u-net architecture for medical image segmentation},
  author={Zhou, Zongwei and Rahman Siddiquee, Md Mahfuzur and Tajbakhsh, Nima and Liang, Jianming},
  booktitle={Deep learning in medical image analysis and multimodal learning for clinical decision support},
  pages={3--11},
  year={2018},
  publisher={Springer}
}

@article{zhang2018road,
  title={Road extraction by deep residual u-net},
  author={Zhang, Zhengxin and Liu, Qingjie and Wang, Yunhong},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={15},
  number={5},
  pages={749--753},
  year={2018},
  publisher={IEEE}
}

@article{najafabadi2015deep,
  title={Deep learning applications and challenges in big data analytics},
  author={Najafabadi, Maryam M and Villanustre, Flavio and Khoshgoftaar, Taghi M and Seliya, Naeem and Wald, Randall and Muharemagic, Edin},
  journal={Journal of big data},
  volume={2},
  number={1},
  pages={1--21},
  year={2015},
  publisher={Springer}
}

@article{briscoe2011conceptual,
  title={Conceptual complexity and the bias/variance tradeoff},
  author={Briscoe, Erica and Feldman, Jacob},
  journal={Cognition},
  volume={118},
  number={1},
  pages={2--16},
  year={2011},
  publisher={Elsevier}
}



% for related works, context
@article{VERFUSS201917,
title = {A review of unmanned vehicles for the detection and monitoring of marine fauna},
journal = {Marine Pollution Bulletin},
volume = {140},
pages = {17-29},
year = {2019},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2019.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X19300098},
author = {Ursula K. Verfuss and Ana Sofia Aniceto and Danielle V. Harris and Douglas Gillespie and Sophie Fielding and Guillermo Jiménez and Phil Johnston and Rachael R. Sinclair and Agnar Sivertsen and Stian A. Solbø and Rune Storvold and Martin Biuw and Roy Wyatt},
keywords = {Unmanned vehicles, Marine animal monitoring, Underwater sound, Environmental impact assessment, Offshore industry},
abstract = {Recent technology developments have turned present-day unmanned systems into realistic alternatives to traditional marine animal survey methods. Benefits include longer survey durations, improved mission safety, mission repeatability, and reduced operational costs. We review the present status of unmanned vehicles suitable for marine animal monitoring conducted in relation to industrial offshore activities, highlighting which systems are suitable for three main monitoring types: population, mitigation, and focal animal monitoring. We describe the technical requirements for each of these monitoring types and discuss the operational aspects. The selection of a specific sensor/platform combination depends critically on the target species and its behaviour. The technical specifications of unmanned platforms and sensors also need to be selected based on the surrounding conditions of a particular offshore project, such as the area of interest, the survey requirements and operational constraints.}
}


@article{korneliussen2016acoustic,
  title={Acoustic identification of marine species using a feature library},
  author={Korneliussen, Rolf J and Heggelund, Yngve and Macaulay, Gavin J and Patel, Daniel and Johnsen, Espen and Eliassen, Inge K},
  journal={Methods in Oceanography},
  volume={17},
  pages={187--205},
  year={2016},
  publisher={Elsevier}
}