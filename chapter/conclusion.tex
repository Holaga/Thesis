\chapter{Conclusion and Future Work}
    This thesis aimed to identify the most informative subset of frequencies used for detecting sandeel, to be used as advice 
    
    
    
    %In this thesis we sought the most informative subset of frequencies to be utilized when classifying sandeel in acoustic data. This was to help identify an optimal choice of frequencies, if the choice of transducers were restricted by for example price or carrying capacity in autonomous vessels. To measure the information lost, we started by producing pseudo labels with an existing automatic acoustic classifier trained to identify sandeel. Then we trained new classifiers based on the same architecture on the same data, but varying subsets of frequencies were used. We could then measure how well these new models could reconstruct the pseudo labels. To find and rank the best performing subset of frequencies, we conducted a greedy search on each subset size used during training. We found that the F1-score increased from a single frequency to two, and then drastically to three, after which only marginal improvements were seen. In particular, the subset containing \textit{18kHz}, \textit{38kHz}, and \textit{200kHz} achieved close to the same performance as using the complete set of six frequencies. Furthermore, the three frequencies mentioned exhibit unique performance compared to the other subsets of equal size. 

    
    In future research we propose that the tests created in this thesis should be introduced to new data and developed further. Only the data from 2019 was used as test data during this work, and our results should be verified across years. Once the \gls{crimac} pipeline is compatible with \textit{.zarr}, it should be tested with the varying frequency subsets, to see if the results compare to ours. As the \textit{background} include unknown backscatter, further work should identify if more labels could be drawn from this class and be available to the model. This could give a more exact performance in regard to sandeel, but depends on which labels are produced when the operators generate the data.
    
    - test on real data
    
    
    
    %- more data
    %- actual labels, alter the training scheme of original model
    %- continue training of single frequency classifiers
    %- bias to planktop and other unknown effects, more classes and have fewer uknown things in the ignore / background class.
    
 